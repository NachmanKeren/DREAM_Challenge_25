{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a MultiSensorRegressor on *all* fold CSVs in `folds_dir`\n",
    "and evaluate on the official leaderboard set\n",
    "`TASK1_Leaderboard_ActualValue.csv`, reporting row‑wise cosine distance.\n",
    "\n",
    "Only minimal code changes compared with the original cross‑validation script:\n",
    "    • concatenate all folds into one training DataFrame\n",
    "    • new validator that runs on the leaderboard file\n",
    "    • loop only over `threshold` values (no fold loop)\n",
    "\n",
    "Everything else stays the same.\n",
    "\"\"\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Imports\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # noqa: F401 (kept for compatibility)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Helper functions\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def load_all_folds(folds_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Concatenate every CSV inside `folds_dir` into one DataFrame.\"\"\"\n",
    "    csv_files = [\n",
    "        os.path.join(folds_dir, f)\n",
    "        for f in os.listdir(folds_dir)\n",
    "        if f.lower().endswith(\".csv\")\n",
    "    ]\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folds_dir}\")\n",
    "    return pd.concat([pd.read_csv(p) for p in sorted(csv_files)], ignore_index=True)\n",
    "\n",
    "\n",
    "def validate_on_leaderboard(model: \"MultiSensorRegressor\", leaderboard_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Predict sensors for the leaderboard set and return cosine‑distance stats and Pearson correlation.\n",
    "    \"\"\"\n",
    "    if not model.combined_csv_path:\n",
    "        raise ValueError(\"`combined_csv_path` not set. Call \"\n",
    "                         \"`create_combined_csv_path_all_folds()` first.\")\n",
    "\n",
    "    # 1. Load leaderboard file and attach labels\n",
    "    test_df = pd.read_csv(leaderboard_path)\n",
    "    stim_def = pd.read_csv(model.stimulus_file)[['stimulus', 'molecule', 'Intensity_label']]\n",
    "    test_df = test_df.merge(stim_def, on='stimulus', how='left')\n",
    "\n",
    "    true_sensor_cols = (test_df\n",
    "                        .drop(columns=['Intensity', 'Pleasantness',\n",
    "                                       'stimulus', 'molecule', 'Intensity_label'],\n",
    "                              errors='ignore')\n",
    "                        .select_dtypes(include=[np.number]))\n",
    "\n",
    "    # 2. Make a temp CSV containing only stimulus column (what predict_new_data expects)\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as tmp:\n",
    "        tmp_path = tmp.name\n",
    "        test_df[['stimulus']].to_csv(tmp_path, index=False)\n",
    "\n",
    "    try:\n",
    "        # 3. Run inference via existing function\n",
    "        pred_df = model.predict_new_data(tmp_path, return_df=True)\n",
    "\n",
    "        common_cols = [c for c in true_sensor_cols.columns if c in pred_df.columns]\n",
    "        true_vals = true_sensor_cols[common_cols].values\n",
    "        pred_vals = pred_df[common_cols].values\n",
    "\n",
    "        # Row‑wise cosine distance (0 = identical, 2 = opposite)\n",
    "        row_cos_dists = cdist(true_vals, pred_vals, metric=\"cosine\").diagonal()\n",
    "        \n",
    "        # Row-wise Pearson correlation\n",
    "        row_pearson_corrs = []\n",
    "        for i in range(len(true_vals)):\n",
    "            # Handle edge cases (constant values, NaNs)\n",
    "            try:\n",
    "                corr, _ = pearsonr(true_vals[i], pred_vals[i])\n",
    "                if np.isnan(corr):\n",
    "                    corr = 0.0\n",
    "            except:\n",
    "                corr = 0.0\n",
    "            row_pearson_corrs.append(corr)\n",
    "        row_pearson_corrs = np.array(row_pearson_corrs)\n",
    "\n",
    "        return {\n",
    "            \"cosine_distance_per_stimulus\": dict(zip(test_df[\"stimulus\"], row_cos_dists)),\n",
    "            \"mean_cosine_distance\": float(row_cos_dists.mean()),\n",
    "            \"pearson_correlation_per_stimulus\": dict(zip(test_df[\"stimulus\"], row_pearson_corrs)),\n",
    "            \"mean_pearson_correlation\": float(row_pearson_corrs.mean())\n",
    "        }\n",
    "    finally:\n",
    "        os.unlink(tmp_path)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Paths & constants\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "base_paths = {\n",
    "    'stimulus_file':   r\"TASK1_Stimulus_definition.csv\",\n",
    "    'folds_dir':       r\"folds\",\n",
    "    'descriptors_file': r\"pom_v11.csv\",\n",
    "    'task2_path':      r'T2_Combined_Dataset.csv',\n",
    "    'output_folder':   r\"DATA\"\n",
    "}\n",
    "\n",
    "LEADERBOARD_PATH = (\n",
    "    r\"TASK1_Leaderboard_ActualValue.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Training + validation\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "means_cosine_dist = []\n",
    "means_pearson_corr = []\n",
    "\n",
    "top_ks = [47]\n",
    "thresholds = [0.27]\n",
    "n_estimatorss = [220]\n",
    "max_depths = [24]\n",
    "GSLF_versions = ['']\n",
    "\n",
    "parameters = [(threshold, top_k, n_estimators, max_depth,\n",
    "               GSLF_version) \n",
    "              for threshold in thresholds \n",
    "              for top_k in top_ks\n",
    "              for n_estimators in n_estimatorss\n",
    "              for max_depth in max_depths\n",
    "              for GSLF_version in GSLF_versions]\n",
    "\n",
    "for threshold, top_k, n_estimators, max_depth, GSLF_version in tqdm(parameters, desc=\"parameters\"):\n",
    "    print(\"\\n══════════════════════════════════════════════════════════════════════\")\n",
    "    print(f\"Training on ALL folds with parameters={(threshold, top_k, n_estimators, max_depth, GSLF_version)}\")\n",
    "    print(\"══════════════════════════════════════════════════════════════════════\")\n",
    "    \n",
    "    # Pre‑computed GSLF dataframe used by your pipeline\n",
    "    processed_gslf_df = pd.read_csv(\n",
    "        rf'C:\\Users\\Asus\\Desktop\\food\\DREAM25\\processed_GSLF{GSLF_version}.csv'\n",
    "    )\n",
    "\n",
    "    \n",
    "    # 1. Create and configure the model\n",
    "    model = MultiSensorRegressor(\n",
    "        stimulus_file    = base_paths['stimulus_file'],\n",
    "        folds_dir        = base_paths['folds_dir'],\n",
    "        descriptors_file = base_paths['descriptors_file'],\n",
    "        rf_params        = {'n_estimators': n_estimators, 'random_state': 42, 'max_depth': max_depth}\n",
    "    )\n",
    "    \n",
    "\n",
    "    # 2. Load EVERY fold as one training set\n",
    "    train_df = load_all_folds(base_paths['folds_dir'])\n",
    "\n",
    "    # 3. Save training set to a temp file (API expects CSV path)\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as tmp:\n",
    "        train_csv_path = tmp.name\n",
    "        train_df.to_csv(train_csv_path, index=False)\n",
    "\n",
    "    try:\n",
    "        # 4. Prepare combined CSV that model uses internally\n",
    "        model.create_combined_csv_path_all_folds(\n",
    "            task2_path        = base_paths['task2_path'],\n",
    "            training_path     = train_csv_path,\n",
    "            stimulus_def_path = base_paths['stimulus_file'],\n",
    "            descriptors_path  = base_paths['descriptors_file'],\n",
    "            output_folder     = base_paths['output_folder']\n",
    "        )\n",
    "                \n",
    "\n",
    "        \n",
    "        # 5. Fit RF + merge GSLF (unchanged logic)\n",
    "\n",
    "        \n",
    "        model.regress_gslf(\n",
    "            processed_gslf_df,\n",
    "            output_path=(\n",
    "                rf\"{base_paths['output_folder']}\\combined_with_gslf_allfolds_thr{threshold}.csv\"\n",
    "            ),\n",
    "            threshold=threshold,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # 6. Validate predictions on the leaderboard set\n",
    "        metrics = validate_on_leaderboard(model, LEADERBOARD_PATH)\n",
    "        mean_cos_dist = metrics[\"mean_cosine_distance\"]\n",
    "        mean_pearson = metrics[\"mean_pearson_correlation\"]\n",
    "        means_cosine_dist.append(mean_cos_dist)\n",
    "        means_pearson_corr.append(mean_pearson)\n",
    "\n",
    "        print(f\"Mean cosine distance (leaderboard) = {mean_cos_dist:.4f}\")\n",
    "        print(f\"Mean Pearson correlation (leaderboard) = {mean_pearson:.4f}\")\n",
    "\n",
    "    finally:\n",
    "        os.unlink(train_csv_path)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Summary\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n======================= FINAL RESULTS =======================\")\n",
    "for (threshold, top_k, n_estimators, max_depth, GSLF_version), dist, corr in zip(parameters, means_cosine_dist, means_pearson_corr):\n",
    "    print(f\"{(threshold, top_k, n_estimators, max_depth)} → cosine distance = {dist:.4f}, Pearson correlation = {corr:.4f}\")\n",
    "\n",
    "print(\"-------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
